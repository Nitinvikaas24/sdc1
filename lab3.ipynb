{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfbce4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import gradio as gr\n",
    "import tempfile\n",
    "\n",
    "def text_to_speech_gtts(text):\n",
    "    tts = gTTS(text)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
    "        tts.save(fp.name)\n",
    "        return fp.name\n",
    "\n",
    "gr.Interface(\n",
    "    fn=text_to_speech_gtts,\n",
    "    inputs=gr.Textbox(label=\"Enter text to convert to speech\"),\n",
    "    outputs=gr.Audio(type=\"filepath\"),\n",
    "    title=\"Text to Speech (gTTS)\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c4f87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Set up API keys for the models\n",
    "OPENAI_API_KEY = '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'\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyDGWtNefh05L6vT1R0WMJo1_I1uOjBlDnQ'\n",
    "\n",
    "# Initialize OpenAI GPT-4 model\n",
    "openai_llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize Google Gemini model (assumed method, check Langchain community for support)\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Conversation buffers for each model\n",
    "openai_memory = ConversationBufferMemory()\n",
    "gemini_memory = ConversationBufferMemory()\n",
    "\n",
    "# Conversation chains for each model\n",
    "openai_chain = ConversationChain(llm=openai_llm, memory=openai_memory)\n",
    "gemini_chain = ConversationChain(llm=gemini_llm, memory=gemini_memory)\n",
    "\n",
    "# Function to choose between models based on user input (or you could set it as per your requirements)\n",
    "def chatbot_fn(message, model_choice=\"OpenAI\"):\n",
    "    if model_choice == \"OpenAI\":\n",
    "        return openai_chain.run(message)\n",
    "    else:\n",
    "        return gemini_chain.run(message)\n",
    "\n",
    "# Gradio interface to interact with both models\n",
    "def create_ui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### Choose LLM Model and Chat\")\n",
    "        \n",
    "        model_choice = gr.Radio([\"OpenAI\", \"Google Gemini\"], label=\"Select Model\")\n",
    "        input_message = gr.Textbox(label=\"Enter your message\", lines=5)\n",
    "        output_message = gr.Textbox(label=\"Response\", lines=5)\n",
    "\n",
    "        input_message.submit(chatbot_fn, inputs=[input_message, model_choice], outputs=output_message)\n",
    "\n",
    "    return demo\n",
    "\n",
    "# Launch the Gradio UI\n",
    "ui = create_ui()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
